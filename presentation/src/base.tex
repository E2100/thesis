\documentclass[screen]{beamer}
\usepackage[T1]{fontenc}
\usepackage[latin1]{inputenc}

% Graphics
\RequirePackage{graphicx}
\RequirePackage{pdfpages}
\RequirePackage{wrapfig}
\RequirePackage{subfig}
\RequirePackage{caption}
\RequirePackage{tikz}
\RequirePackage{pgf}
\RequirePackage{pgfplots}
\usetikzlibrary{arrows,shapes,positioning,plotmarks}

% Color
\RequirePackage{xcolor}
\definecolor{red}{HTML}{990000}
\definecolor{green}{HTML}{336633}
\definecolor{black}{HTML}{000000}
\definecolor{lightgray}{HTML}{CCCCCC}
\definecolor{gray}{HTML}{999999}
\definecolor{darkgray}{HTML}{666666}

\usepackage{setspace}

% Bruk NTNU-temaet for beamer (her i bokmålvariant), alternativer er
% ntnunynorsk og ntnuenglish.
%\usetheme{ntnuenglish}

%\setbeamertemplate{footline}[ntnu theme nologo]
 
% Angi tittelen, vi gir også en kortere variant som brukes nederst på
% hver slide:
\title[Adaptive Aggregation of Recommender Systems]%
{Adaptive Aggregation of\\Recommender Systems}

% Angir foredragsholder, også en (valgfri) kortversjon i
% hakeparanteser først som kommer nederst på hver slide:
\author{Olav Bj{\o}rk{\o}y}

% Institusjon. Bruk gjerne disse slik det passer best med det du vil
% ha.  Valgfri kortversjon her også
\institute[NTNU]{Norwegian University of Science and Technology\\
\vspace{0.5em}
Department of Computer and Information Science\\
\vspace{2em}
India-Norway Workshop on\\
\vspace{0.5em}
Web Concepts and Technologies\\
\vspace{0.5em}
October 3rd, 2011}

% Datoen blir også trykket på forsida. 
%\date{October 3rd, 2011}
\date{} % Bruk denne hvis du ikke vil ha noe dato på forsida.

% Fra her av begynner selve dokumentet
\begin{document}

\begin{frame} 
  \titlepage
\end{frame} 


\begin{frame}
  \frametitle{Terminology}
  \begin{tabular*}{1\textwidth}{ l l }
    \textbf{term} & \textbf{description} \\
    \hline
    $u$ & a user \\
    \hline
    $i$ & an item (article, website, movie, email...)\\
    \hline
    $r$ & the rating (relevance, utility, other domain term)\\
    \hline
    $m$ & a method/algorithm for predicting ratings.\\
    \hline
    $p(m,u,i)$ & rating prediction from method $m$ for $(u,i)$\\
    \hline
  \end{tabular*}
\end{frame}

\begin{frame}
  \frametitle{2006: The Netflix Challenge}
    \begin{itemize}
      \item USD 1MM prize for a 10\% accuracy improvement.\\
      \item Breakthrough: Combining methods from many teams.\\
      \item Team BellKor finally achieved a 10.06\% improvement by combining \textbf{107} different recommender algorithms.
    \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Today: Web Search}
    \begin{quote}
      "Today we use more than 200 signals, including PageRank, to order websites, and we update these algorithms on a weekly basis."\\
      --- Google\\ \color{gray}{\tiny(\url{google.com/corporate/tech.html})}
    \end{quote}
    \vspace{2em}
    \begin{quote}
      "We use over 1,000 different signals and features in our ranking algorithm."\\
      --- Microsoft Bing\\ \color{gray}{\tiny(\url{bing.com/community/site_blogs/b/search/archive/2011/02/01/thoughts-on-search-quality.aspx})}
    \end{quote}
\end{frame}


\begin{frame}
  \frametitle{Why multiple algorithms?}
  \begin{itemize}
    \item The unreasonable effectiveness of data
    \item Capture more predictive aspects of existing data.
    \item Specialized predictors for subsets of data.
  \end{itemize}
  \vspace{2em}
  \begin{quote}
    "Quite frequently we have found that the more accurate predictors are less useful within the full blend."\\
    --- Bell, R., Koren, Y., and Volinsky, C. (2007) (Netflix)
  \end{quote}  
\end{frame}

\begin{frame}
  \frametitle{The Problem: Latent Subjectivity}
  \begin{eqnarray}
    \hat{r}_{u,i} = \sum_{m \in M} w_{m} \times p_{r}(m,u,i)
  \end{eqnarray}
  \begin{itemize}
    \item Generalized optimal weights.
    \item Treats all users and items the same.
    \item Varying accuracy across users and items.
    \item Methods are chosen by the system, not the users or items.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{The Problem: Latent Subjectivity}
  \huge
  \linespread{2}{
    Systems that insist on being adaptive in a certain way
    are not really adaptive at all.
  }
\end{frame}

\begin{frame}
  \frametitle{Adaptive Recommenders}
  \begin{itemize}
    \item Multiple rating algorithms weighed by contextual accuracy.
  \end{itemize}
  \begin{eqnarray}
    \hat{r}_{u,i} = \sum_{m \in M} p_{w}(m,u,i) \times p_{r}(m,u,i)
  \end{eqnarray}
  \begin{itemize}
    \item $p_r$: predicted rating from method $m$ for $(u,i)$.
    \item $p_w$: predicted optimal weight for method $m$ for $(u,i)$.
    \item We can use recommender systems for \textbf{both} $p_r$ and $p_w$.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Adaptive Recommenders}
  \input{figure.layers}
\end{frame}

\begin{frame}
  \frametitle{Training phase}
  
  \begin{enumerate}
    \item Split data into two sets: $(d_m,d_e)$.
    \item Use $d_m$ to train the rating predictors.
    \item Create an \emph{error matrix} for the rating predictors and $d_e$. 
    \item The error matrix now holds known errors for some $(m,u,i)$.
    \item Train error predictors from the error matrix.
  \end{enumerate}
  
  \begin{eqnarray}
    \forall (u,i,r) \in (d_e - d_m): E(m)_{u,i} = |r - p(m,u,i)|
  \end{eqnarray}
\end{frame}

\begin{frame}
  \frametitle{Training phase}
  
  \begin{equation*}
     R_{u,i} =
     \begin{pmatrix}
      r_{1,1} & r_{1,2} & \cdots & r_{1,i} \\
      r_{2,1} & r_{2,2} & \cdots & r_{2,i} \\
      \vdots  & \vdots  & \ddots & \vdots  \\
      r_{u,1} & r_{u,2} & \cdots & r_{u,i}
     \end{pmatrix}
    \end{equation*}

  \vspace{1em}
  
    \begin{equation*}
     E_{u,i} =
     \begin{pmatrix}
        e_{1,1} & e_{1,2} & \cdots & e_{1,i} \\
        e_{2,1} & e_{2,2} & \cdots & e_{2,i} \\
        \vdots  & \vdots  & \ddots & \vdots  \\
        e_{u,1} & e_{u,2} & \cdots & e_{u,i}
     \end{pmatrix}
    \end{equation*}
    
    \vspace{1em}
    \begin{itemize}
      \item $\mathrm{train(m, R)} \rightarrow \mathrm{rating\_predictor}$
      \item $\mathrm{train(m, E)} \rightarrow \mathrm{error\_predictor}$
    \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Prediction phase}
  
  \begin{enumerate}
    \item Predict ratings $\hat{r}_{(u,i,m)}$.
    \item Predict errors $\hat{e}_{(u,i,m)}$.
    \item Create adaptive weights by inversing the normalized errors.
    \item Sum the weighted predictions to get the final $\hat{r}$.
  \end{enumerate}  
\end{frame}

\begin{frame}
  \frametitle{Prediction phase}
  \begin{equation}
    \label{eq:adaptive}
    \hat{r}_{u,i} = \sum_{(m_{e}, m_{r}) \in M} (1 - 
    \frac{
      p(m_{e},u,i)
    }{
      error(u,i)
    }) \times p(m_{r},u,i)
  \end{equation}
  \vspace{2em}
  \begin{equation}
    error(u,i) = \sum_{m_e \in M} p(m_e,u,i)     
  \end{equation}
\end{frame}

\begin{frame}
  \frametitle{Experiment}
  \begin{itemize}
    \item RMSE values for basic recommenders, simple aggregations and adaptive aggregation.
    \item Used the Movielens movie rating dataset.
    \item See paper for more details.
    \vspace{2em}
    \begin{equation}
      \mathrm{RMSE}(\hat{R},R)
      = \sqrt{\frac{
          \sum_{i=1}^{n} (\hat{R}_i - R_i)^2
        }{
          n
        }}
    \end{equation}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Results}
  \input{table.movielens}
\end{frame}

\begin{frame}
  \frametitle{Results}
  \input{plot.movielens}
\end{frame}

\begin{frame}
  \frametitle{Results}
  \input{plot.sigma}
\end{frame}

\begin{frame}
  \frametitle{Limitations}
  \begin{itemize}
    \item Lots of added complexity for fairly unknown improvement.
    \item Only tested on a few datasets, no real world situations.
    \item Only compared to simple aggregation methods.
    \item Neither the aggregators nor the basic recommenders were
      heavily optimized to the domain of the dataset.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Adaptive Recommenders}
  \begin{itemize}
    \item Combine disjoint algorithms
    \item Weigh recommenders by predicted accuracy.
    \item Accuracy predictions are contextually dependent on $(u,i,m)$.
    \item \emph{Any} applicable recommender becomes a worthy addition.
  \end{itemize}
  \vspace{2em}
  See paper for more references and results.
\end{frame}

\end{document}