\section{Related Work}

There are many ways of predicting the
relevance of an item to a user. 
In fact, judging by the number of different approaches,
the only limiting factor seems to be the different 
patterns researchers discover in available data.
We will explain many of these systems throughout this paper.
See 
\cite{Adomavicius2005}, \cite{Pazzani2007}, \cite{Schafer2007} 
or \cite{Bjorkoy2010d} for a comprehensive exploration 
of different types of recommenders.

We are more interested in current approaches to recommender prediction aggregation,
that is, combining multiple predictions made by different algorithms.
\cite{Aslam2001} describes a number of simple approaches to prediction aggregation.
Min, max and sum models combine the individual predictions in some way, 
or select one or more of the results as the final prediction. 
Other models use the average, or log-average of the different methods.
The linear combination model trains weights for each predictor, and weighs predictions accordingly.
At slightly more complex approach is to train a logistic regression model \cite[p3]{Aslam2001}
over a training set, in an effort to find the combination that gives the lowest possible error.
This last method improved on the top-scoring predictor by almost 11\% \cite[p3]{Aslam2001},
showing that even fairly simple combinations have merit.

Early approaches in recommender systems dabbled in aggregating content-based and collaborative approaches.
\cite{Claypool1999} combined the two approaches in an effort to thwart problems with each method.
Collaborative filtering (CF) methods have problems rating items for new users, radically different users or when dealing with very sparse data.
Content-based (CB) methods do not have the same problems, but are less effective than CF in the long run, as CB does not tap into the 
knowledge of other users in the system --- knowledge that out-performs simple content analysis.
In \cite{Claypool1999}, the two types of recommenders were used to create a simple weighted result.

Generally, methods for aggregating predictions in the field of machine learning is called \emph{ensemble methods} (EM) \cite[p1]{Dietterich2000}.
While most often used to combine classifiers that classify items with discrete labels,
these methods are also used for aggregating numerical values (see the numerical parts of \cite{Breiman1996}).
Approaches include \emph{bootstrap aggregation} (bagging) and \emph{boosting} 
for selecting proper training and testing sets,
and creating a \emph{mixture of experts} for combining the predictors
\cite[p27]{Polikar2006}.

\cite{Bell2007} took method aggregation to its logical conclusion when winning the Netflix Challenge,
by combining 107 individual results from different recommenders: 
"We strongly believe that the success of an ensemble approach depends on the ability of its various predictors to expose different, 
complementing aspects of the data. Experience shows that this is very different from optimizing the accuracy of each individual predictor. 
Quite frequently we have found that the more accurate predictors are less useful within the full blend." \cite[p6]{Bell2007}

See \cite{Bjorkoy2011} for more background theory and related work.
