\section{Recommenders}

Standard recommender systems will be used for both the basic predictions, and the accuracy estimations, as described in Chapter \ref{chap:methods}.
Naturally, we need a number of different RSs, preferably ones that consider
disjoint patterns in the data. Table \ref{table:results:methods}
gives a short overview of the recommender systems we shall employ.
All three experiments will use every recommender in this table.
This section gives a short introduction to these methods.
See Section \ref{sec:recommender} for more information on RSs, 
and Appendix \ref{appendix:implementation} for details on how these were implemented in this system.


\subsection{Basic Recommenders}

\begin{table}[t]
  \begin{tabular*}{\textwidth}{ l l l l }
    \toprule
    ~Â & \emph{method} &  \emph{algorithm} & \emph{description} \\
    \midrule
    S & svd1          & SVD                   & ALSWR factorizer, 10 features. \\
    S & svd2          & SVD                   & ALSWR factorizer, 20 features. \\
    S & svd3          & SVD                   & EM factorizer, 10 features. \\
    S & svd4          & SVD                   & EM factorizer, 20 features. \\
    S & slope\_one    & Slope One             & Rating delta computations. \\
    S & item\_avg     & Baseline              & Based on item averages. \\ 
    S & baseline      & Baseline              & Based on user and item averages.\\ 
    S & cosine   	    & Cosine similarity     & Weighted ratings from similar items.\\ 
    S & pcc       	  & Pearson Corr.         & Weighted ratings from similar users.\\
    \midrule
    A & median    	  & Aggregation           & Median rating from the above methods. \\
    A & average    	  & Aggregation           & Average rating from the above methods. \\
    A & adaptive      & Adaptive agg.         & Accuracy predictions from error models. \\
    \bottomrule
  \end{tabular*}
  \caption[Adaptive Modeling Methods]{
    Adaptive modeling methods: a short overview of the recommender methods
    used in our experiment.
    Each recommender is used in every experiment. 
    See Section \ref{sec:recommender} for more information.
  }
  \label{table:results:methods}
\end{table}

As seen in Table \ref{table:results:methods}, we have two types of recommenders.
First, we have the basic recommenders, denoted by \emph{S} in the table.
Each of these systems look at varying data patterns to predict ratings.
We chose this wide range of recommenders for just this reason.
As previously explained, the performance of aggregation methods
are more dependent on the dissimilarity of the basic recommenders
than their individual performance \cite[p.6]{Bell2007}.

Let us briefly explain how each basic RS works.
The SVD methods look for global patterns in the data 
by reducing the ratings-space into a concept-space.
By reducing this space, the algorithm is able to find
latent relations, such as groups of movies that has the same
rating pattern, or groups of users that often rate in a similar manner.
For the SVD methods, the factorizers refers to algorithms used to factorize the ratings matrix
(see Section \ref{subsec:recommender:examples}).

The Slope One and baseline algorithms look at average
ratings for items and from users, and use these to predict ratings.
These are simple algorithms that often perform as well
as more complex approaches.

The cosine similarity algorithm looks for items that are rated
similarly by the same users, and infers item similarity from this measure.
New ratings are then predicted by taking known ratings of other items,
weighted by their item's similarity to the new item.
This is based on the same method used in the previously introduced vector space model.

The PCC algorithm employs yet another approach. This algorithm,
similar in strategy to the cosine similarity algorithm,
looks for users with similar rating patterns.
The similarity is measured with the Pearson Correlation Coefficient.
Predictions are created by collecting ratings from similar users
of the item in question, weighted by their respective similarity.
See Section \ref{sec:recommender} for more 
detailed information on how these recommenders work. 

The main difference between our recommenders are the scope of the patterns they leverage.
The SVD and baseline methods look at global effects, such as latent categories
and overall rating averages.
The cosine similarity and PCC algorithms look at smaller clusters of similar
users and items, and compute an average rating weighted by 
similarities of elements.
This wide range of recommender should give us the desired
effect of looking at disjoint rating patterns.


\subsection{Adaptive Recommenders}

The second type of recommenders are the aggregation methods, 
that combine the result of each of the basic system
(the methods below the middle line in Table \ref{table:results:methods},
denoted ``A'').

The first two of these methods are simple aggregation approaches.
These will be used to test hypothesis H2.
The median aggregation method choses the median value of the predictions
produced by the standard recommenders.
Similarly, the average aggregation method takes the mean of the
standard predictions.
While not complex in nature, these methods
will help us see how our method compares to simple aggregation techniques.

The last entry in Table \ref{table:results:methods}
refers to our technique. 
This is the recommender outlined by the algorithms
in Chapter \ref{chap:methods},
that create secondary accuracy estimating recommender systems,
in order to adaptively weigh the basic recommenders.
All the aggregation approaches, including our technique,
employ every basic recommender system described so far.

As explained in Section \ref{sec:usermetamodeling},
any basic recommender system can be used for the adaptive method.
The only difference is how this method is trained.
While the basic methods are trained using the ratings matrix,
the adaptive methods are trained using the error matrix,
as seen in Listing \ref{code:training}.
We have as many possibilities for choosing
the adaptive recommenders as the basic recommenders.

For our experiment, we chose SVD recommenders for the adaptive models.
That is, the basic recommender methods get secondary 
accuracy predicting recommenders, which in this case are standard SVD-based recommender systems.
The SVD recommender is a natural choice in this case,
since we wish to uncover latent patterns of accuracy for each model.
SVD recommenders look for global patterns in the data,
which in this case would mean situations where a standard RS
works especially well for, or does not work for,
a set of users, items, or a combination of these.

It is important to note that the same configuration of recommenders was used for all three experiments.
Neither the basic nor the aggregate or adaptive recommenders were heavily tailored
to the datasets. To be sure, higher performance could probably have been achieved
by tailoring the recommenders to the available data. 
However, as our goal is to compare our finite set of methods, 
we are currently only interested in how they perform compared to each other.

As with the basic recommenders, the same SVD recommender configuration was used 
for the adaptive layer in every experiment.
We chose to use en EM-factorizer to perform the actual decomposition,
consisting of 20 features. The decomposition was performed by 20 iterations.
See \ref{subsec:recommender:examples} for more information on how SVD-based recommenders work. 
The choices of recommenders will be further discussed
in Chapter \ref{chap:discussion}.

