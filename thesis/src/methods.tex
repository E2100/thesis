In this chapter we will build our approach to user modeling:
blending multiple predictors on per-user basis.
We will first explain the reasoning behind our hypotheses,
before we present a method for personalized aggregation.

This \emph{meta model} is then used to perform prediction aggregation in a recommendation scenario,
and rank aggregation in an information retrieval scenario.
%Chapter \ref{chap:results} will experiment with these solutions,
%before we discuss and draw conclusions in the final chapter.


\section{Latent Subjectivity}

As seen in Chapter \ref{chap:theory}, 
there are lots of ways of predicting unknown relevance scores. 
In fact, judging by the number of different approaches,
the only limiting factor seems to be the different 
patterns and relations researchers discover in the available data.
Different methods leverage the data in different ways
to achieve their goals of accurate predictions

As seen in Section \ref{sec:aggregate},
aggregate modeling is used to combine different, complimenting
methods into one coherent system.
By leveraging what we shall call \emph{disjoint patterns}
in the data, several less than optimal predictors
can be combined in a way that outperforms the best
of the combined predictors.

However, there exists an underlying subjectivity to 
relevance prediction that is seldom discussed.
When a researcher or developer elects to use some modeling method
in order to represent users of their system,
a concious selection of applicable measures is made.
Consider the following relevance judgements:

\begin{itemize*}
  \item PageRank \citep{Bender2005} assumes that the relevance of a web page is 
  represented by its authority, as computed from inbound links from other sites.
  \item When providing personalized search results, one ranking signal may be 
  the social connections of the current user. Items deemed relevant by the user's 
  peers will then recieve a boosted ranking (e.g. \cite{Carmel2009}).
  \item When determining the relevance of an email, one predictor might be based
  on how often the sender sends emails to the current user.
  \item When recommending movies, one predictor may be based on the ratings
  of users with similar profile details. Another predictor might be 
  dependent on some feature, e.g. production year of well liked movies.
  \item Recommendations based on the Pearson Coefficient \cite[p11]{Segaran2007}
  assumes that the statistical correlation between user ratings defines their 
  similarity.
\end{itemize*}

Are these metrics subjective? 
While the methods themselves do not discriminate, their selection
reflects how whoever created the system assumes how each user
can and \emph{should} be modeled. This \emph{latent subjectivity} is not desirable.
For example, While one user might appreciate a social
influence in their search results, another user might not.
While one user might find frequency of communication maps well to relevance,
another might not. 
One user might feel the similarity of movie titles are a good predictor,
while another might be more influenced by production year.
The exact differences are not important --- what is important is that they exist.

Another way of explaining latent subjectivity is that 
\emph{user modeling methods are dependent on the subjective assumptions of their creators}.
In other words, each modeling method use some aspect of available data to make predictions,
and the selective importance of each of these methods is made by whoever creates the system,
not by the users themselves.
Aggregate modeling methods face the same problem of misplaced subjectivity: 
Aggregation is done on a generalized, global level,
where each user is expected to place the same importance on each modeling method.
While the aggregation is of course selected to minimize some error over a testing set,
the subjective nature remains: The compiled aggregation is a generalization,
treating all users the same --- hardly a goal of user modeling.

We propose a method where these descisions are left to each user,
providing an extra level of abstraction and personalization.
This leaves the subjective nature of modeling method selection where it should be:
In the hands of each individual user.

If each method is \emph{only used} based on how well it performs for each user,
any possibly applicable user modeling method suddenly becomes a worthy addition.
Consider the following two questions:

\begin{enumerate*}
  \item What combination of which methods will accurately predict unknown scores?
  \item Which methods could possibly help predict a score for a user?
\end{enumerate*}

The first question is what has to be considered in traditional modeling aggregation:
First a set of applicable methods leveraging disjoint patterns must be selected. 
Then, an optimal and generalized combination of these must be found,
most often through painstaking trial and error.

The second question is quite different. 
Instead of looking for an optimal set of methods and an optimal combination,
we look for the set of \emph{any applicable method} that \emph{some users} might find helpful.
We believe this is a much simpler problem: 
instead of trying to generalize individuality,
it should be embraced, by allowing users to implicitly and automatically select which methods they prefer.


\section{Hypotheses}

In light of these assumptions, we will try to answer the following hypotheses:

$H_{0}$: The accuracy of user-item relevance predictions can be improved
by blending multiple modeling methods on a per-user basis.

$H_{1}$: A per-user aggregation method can outperform global and generalized 
blending methods.

$H_{2}$: The result set from an information retrieval query
can be personalized by blending multiple modeling methods on a per-user basis.




\section{Meta Modeling}

\subsection{Modeling Methods}

A system for aggregate user modeling (AUM) can be described as a quintuple:

\begin{equation*}
 R_{u,i} =
 \begin{pmatrix}
  r_{1,1} & r_{1,2} & \cdots & r_{1,i} \\
  r_{2,1} & r_{2,2} & \cdots & r_{2,i} \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  r_{u,1} & r_{u,2} & \cdots & r_{u,i}
 \end{pmatrix}
\end{equation*}

\begin{eqnarray*}
  \mathrm{AUM} &=& (Items, Users, Ratings, Framework, Methods, Aggregation)\\
               &=& (I,U,R,F,M,A).
\end{eqnarray*}

We have a set of $Items$ and a set of $Users$.
There is also a set of $Ratings$: each user $u \in U$ can \emph{rate} an item $i \in I$.
We use the term "rating" loosely --- other applicable and equivalent terms include \emph{relevance}, \emph{utility},
\emph{connection strength} or \emph{ranking}. In other words, this is a measure of what a user thinks of an item
in the current domain language. However, since "rating" will match the case study we present later in this chapter,
that is what we shall use.

As we are dealing with multiple approaches to user modeling, we have a set of $Methods$ that each create their own
user models. Each model $m \in M$ are used to compute predictions, i.e. estimations of unknown ratings.
As demonstrated in Chapter \ref{chap:theory}, there are many different forms of user modeling,
that each consider differents aspects of the available data: the users, items and ratings, as well as 
other sources such as intra-user connections in social networks or intra-item connections in information retrieval systems.

The $Aggregation$ part of this quintuple refers to how the predictions from the different methods are combined
into one blended prediction. 

\subsection{Information Retrieval Signals}

\subsection{Multilayer Perceptron}

\subsection{Application}



\section{Prediction Aggregation}

\subsection{Modeling Phase}

\subsection{Prediction Phase}

\subsection{Implementation}



\section{Rank Aggregation}

\subsection{Modeling Phase}

\subsection{Prediction Phase}

\subsection{Implementation}



\begin{comment}
\clearpage

\section{Modeling}

A system for aggregate user modeling (AUM) can be described as a quintuple:

\begin{eqnarray*}
  \mathrm{AUM} &=& (Items, Users, Ratings, Framework, Methods, Aggregation)\\
               &=& (I,U,R,F,M,A).
\end{eqnarray*}

We have a set of $Items$ and a set of $Users$.
There is also a set of $Ratings$: each user $u \in U$ can \emph{rate} an item $i \in I$.
We use the term "rating" loosely --- other applicable and equivalent terms include \emph{relevance}, \emph{utility},
\emph{connection strength} or \emph{ranking}. In other words, this is a measure of what a user thinks of an item
in the current domain language. However, since "rating" will match the case study we present later in this chapter,
that is what we shall use.

As we are dealing with multiple approaches to user modeling, we have a set of $Methods$ that each create their own
user models. Each model $m \in M$ are used to compute predictions, i.e. estimations of unknown ratings.
As demonstrated in Chapter \ref{chap:theory}, there are many different forms of user modeling,
that each consider differents aspects of the available data: the users, items and ratings, as well as 
other sources such as intra-user connections in social networks or intra-item connections in information retrieval systems.

The $Aggregation$ part of this quintuple refers to how the predictions from the different methods are combined
into one blended prediction. 
This paper presents a per-user, individual approach to this aggregation. However, there are many, simpler ways of computing the
combined prediction. For example, a weighted average could be constructed as simply as 

\begin{equation*}
  \hat{r}_{ui} = \sum_{m \in M} w_m \cdot p_m(u,i) 
  \quad \text{where}
  \quad 0 \leq w \leq 1, 
  \quad \sum_{i} w_i = 1.
\end{equation*}

Here, $\hat{r}_{ui}$ is the predicted rating from user $u$ of item $i$.
$w_m$ is the weight of method $m$ and $p_m(u,i)$ is the predicted rating from method $m$.
Of course, the weights of each method have to be estimated in advance.
By creating a training and a testing set from already known ratings, we can estimate the weights
that minimize the error over the testing set. 
This can for example be done through \emph{regression} or the \emph{least squares method}.
(TODO: Refs)




\clearpage

\begin{equation*}
  \mathrm{AM} = (Items, Users, Framework, Methods, Aggregation)
\end{equation*}

\section{Prediction}

User-weighted average

\begin{equation*}
  \hat{r}_{ui} = \sum_{m \in M} w_{um} \cdot p_m(u,i)
\end{equation*}


Higher-order

\begin{equation*}
  \hat{r}_{ui} = f_{u}[ P_{M}(u,i) ]
\end{equation*}





\section{Implementation}      

\end{comment}


