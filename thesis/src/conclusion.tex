\label{chap:discussion}

This chapter will discuss the implications of our results.
While our hypotheses may be answered,
it is important to clarify what we have actually found out,
and what limits there is to this knowledge.
We will also summarise the contributions of this thesis,
and suggest possible future work.


\section{Implications}      

Our central assumption is that modern recommender systems 
are constrained by their misplaced subjectivity.
Each system selects some measures to model its users, 
based on how they think each user and item \emph{should} be modeled.
We believe this selection should be left to each user:
differing users and items will require adaptive recommender algorithms that
consider the context before making predictions.

Adaptive recommenders can help solve this problem.
In a collection of possible recommender algorithms, each is adaptively used based 
on how well it performs for the item and user in question.
The experiments of the previous chapter shows the promise of this technique.
However, there are lots of use cases not yet considered.

It should be clear that adaptive recommenders would work best in situations where
we have a wide range of diverse algorithms that can infer the relevance of an item to a user.
For users, social connections is a good example: whether or not social connections should influence
recommendations or personalized search results is a contentious topic.
Naturally, a system where each user's personal opinion determines if these connections are used is desireable.

This implication extends to the items that should be recommended:
As evident by the field of information retrieval,
there exists many ways of considering the relevance of an item. 
Each of these algorithms can be based on a number of attributes, for example
temporal information, geography, sentiment analysis, topic or keywords.
It is not a huge leap to assume that each of these algorithms may have
varying levels of accuracy for each individual item.
Adaptive recommenders can help solve this problem by adaptively 
combining the recommenders based on individual item performance.

Hypothesis H1 was confirmed by showing that adaptive recommenders
can outperform standard single-approach recommenders.
We achieved lower total RMSE scores across each of our datasets,
which would imply that adaptive recommenders
reliably performs better than our tested standard recommenders.

Hypothesis H2 was confirmed by showing that adaptive recommenders
can outperform simple, generalized aggregation approaches.
While our standard aggregators were simple,
this result is promising.
However, the real test would be to use our approach
in a situation with even more differing recommender systems.

Hypothesis H3 was confirmed by showing that our approach
can be used to provide personalized search.
While we did not strictly evaluate the quantitative performance
of this approach, our results show that different
prioritisations of the IR scores can cope with many different use cases.
The key insight is that the IR score can be seen as a signal
on the same level as the adaptive recommenders,
gaining the power of query matching and relevance matching
in the same results set.

With adaptive recommenders, both the methods layer and the adaptive layer consists of standard recommender algorithms.
Because we use ratings matrices for the taste models and error matrices for the weight estimations,
we can use the same algorithms for both tasks.
Using known algorithms for this new task is beneficial:
they are known to work, enjoy multiple implementations
and are already understood and battle-tested in many different systems.


\section{Limitations}

There are some important general limitations to our research
related to the 
(1) complexity of our method, 
(2) our choice of data and evaluation metrics, 
(3) the general usefulness of this approach, and
(4) common issues with recommender systems.

(1) Complexity: As our approach is more complicated than standard recommenders,
it is worth questioning if its gains are worth the extra complexity.
This depends on the basic recommenders that are to be combined.
If the system is made up by many different recommenders,
that each user might place varying importance on,
and that may have varying success with each item,
adaptive recommenders may provide gains in accuracy.

On the other hand, if the recommenders are simple in nature,
and look at similar patterns in the data,
generalized aggregation methods might be more applicable.
Clearly, the performance gains in our experiments
are not substantial enough to declare anything without reservation.
While we believe this technique has potential,
without real-world success stories, it is hard
to suggest that our method is particularly better
than a simple standard recommender.

(2) Evaluation: we chose traditional datasets and evaluation metrics
to validate the adaptive recommenders technique.
While our initial results are promising, it is important to stress
that this is only one test on one dataset. Considering the vast scope
of applicable data, and the number of ways these results many be 
evaluated, the results must be seen for what they are:
initial and preliminary explorations of a new technique
that has yet to be proved useful in the real world.

As mentioned in Chapter \ref{chap:theory}, the scale of known ratings is another concern.
When we have a set of explicit ratings given by users, these are often
given in discrete steps, and not on a continuous scale.
As known from the field of statistics, when using ordinal scales,
the significance of each steps are not necessarily equal.
For instance, on a scale from 1 through 5, the difference
between 2 and 3 might not be as significant as the difference between 4 and 5.
This is a limitation of many recommender system, apparent by the algorithms they use:
most do not consider the implications of ordinal data.
Naturally, in a real-world system, this limitation has to be considered.

(3) Usefulness:
When considering the additional complexity of our approach,
a natural response is whether or not current approaches
to recommender systems are good enough.
We do not think so: information overload is such a nuanced problem 
that the only solution lines in intelligent, adaptive systems.
However, as most of today's recommender systems 
perform quite simple tasks, they may be more
than good enough for their purpose.

This will always be a trade-off, between complexity and required accuracy.
As in many other cases, each of the systems described in this thesis
have their use cases. In the end, the requirements of each system
must decide which method best suit their needs.

(5) Common issues:
The topic of recommenders and adaptive systems in general
raise a number of questions which is outside the scope of this thesis.
For example, user privacy is a big issue.
Whenever we have a system that tries to learn the tastes, habits and
traits of its users, how each user will react to this must be considered.
This is often a trade-off between adaptability and transparency.
The most adaptive systems will not always be able to explain to the users
what is going on and what it knows about each person,
especially when dealing with emergent behavior based on 
numerical user models.

Another important issue is the usability of autonomous interfaces.
Whenever recommenders are used for more than simple lists of items,
there is a question of how easy the resulting system will be to use.
As mentioned in Chapter \ref{chap:theory},
unpredictability is the enemy of usability.
Creating an autonomous system that is also
predictable is a serious challenge, and a common trade-off.

While a thorough discussion of privacy and usability is 
outside our scope, they are both important limitations to considered
when using a recommender system.

In addition to the general limitation, each of our experiments
carries a few drawbacks.

Hypothesis H1 was only tested against a limited number of standard recommenders.
The key word is standard: these recommenders were not heavily customized
to fit the available data. As in all machine learning,
achieving relatively good performance is quite simple.
Any improvements above this standard requires deep domain knowledge,
and methods customized to the problem at hand.
In an actual system, the adaptive recommenders should be tested
against carefully selected standard recommenders,
optimized for the current domain.

Hypothesis H2 was only tested against simple aggregators.
Many more complex aggregations are possible,
for example by solving the problem of finding
optimal generalized weights for each method.
While our tests show the basic viability of our approach,
more testing against complex aggregation functions
is still required.

Hypothesis H3 was only tested in a qualitative way.
Ideally, if one has access to detailed query logs,
user profiles and click-through information,
a quantitative experiment should be performed.
Such an experiment would have to be done
to compare our approach to other ways of performing
personalized search.
However, we believe these initial results
help demonstrate the probable value of our approach
in this domain.


\section{Contributions} 

We have made two main contributions with this thesis:
(1) described the latent subjectivity problem and
(2) developed the technique of adaptive recommenders.

(1) The latent subjectivity problem is one we think hinders
standard recommender systems reaching their full potential.
As far as we know, this problem has not been described
in the context of recommender systems.
The main choice for any such system is how to predict unknown ratings.
To do this, a pattern in the available ratings data must be leveraged.
These patterns are plentiful, and which works best is dependent on
each user and item in the system.
Modern aggregation recommenders utilize many patterns, but on a generalized
level, where each user and item is treated the same.
This underlying subjectivity leads to a mismatch between the notions
of whoever developed the systems, and the users and items of the service.

The latent subjectivity problem extends to any ensemble learning system
(as those described in \cite{Polikar2006}) that blends multiple 
algorithms to leverage patterns.
Whenever we have multiple algorithms that work on a set of items
(and possibly users), there is a question of how accurate each
approach will be for each item.
Averaged or generalized weighted approaches will always
chose the combination that performs best \emph{on average},
with little concern to the uniqueness of items (and users).
In other words, this is a comprehensive problem
that may be discovered amongst many machine learning techniques.

(2) Adaptive recommenders is our attempt to solve the latent subjectivity problem.
As far as we know, this type of adaptive prediction aggregation has not been done before.
Chapter \ref{chap:results} showed that an aggregation that combines predictions based
on estimated accuracy can outperform both standard recommenders and simple aggregation approaches.
Our technique is strengthened by the fact that standard recommender algorithms
are used for the accuracy estimations.
This is the core insight of this thesis: 
by creating error models for each recommender, we can use this to predict
its accuracy for each user/item combination.
These predictions can then be used to weigh each combined algorithm accordingly.

As far as the latent subjectivity problem extends to any ensemble learning system,
the adaptive aggregation part of adaptive recommenders can be used to 
create better combinations of many types of predictors.
Whenever we have a set of algorithms producing a set of predicted values
based on items, a set of aggregating recommenders can model the probable
errors of these approaches, based on each individual item.
This leads to adaptive ensembles that should outperform generalized approaches.
Because of this, the technique build in this thesis should be 
applicable in situations other than recommender systems.

While the experiments of Chapter \ref{chap:results} show the general viability of adaptive recommenders,
we believe there are greater opportunities in systems where there  are even more diverging
patterns to be leveraged. The prime examples of this are systems that may or may 
not use social connections between users, and systems which predict the 
relevance of widely varying items.


\section{Future Work}      

We have only shown the basic viability of adaptive recommenders,
and how they can outperform traditional approaches on traditional datasets.
This section outlines a few interesting research topics
which should shed more light on the subject.


\paragraph{Choosing Different Adaptive Recommenders}
We chose to use SVD-based recommenders for the adaptive part of our adaptive approach.
The main reason for this is that we are looking for global traits of the data
when performing accuracy estimations. In other words, we wish to identify
clusters of users and items for which each algorithm may or may not be suited.

However, as the adaptive recommenders can utilize any standard recommender system
to model the errors of another recommender, it would be interesting to perform
a more in-depth study of how different choices for the adaptive layer
influence the final system.
There are many more recommenders that also look at global patterns
that might be well suited for this task.

Another interesting question is whether other machine learning methods can be used for the adaptive layer.
For example, using neural networks to estimate non linear aggregation functions for each user would be an interesting approach.
This was attempted earlier in our research, but abandoned when recommenders were found to produce
better results in a more elegant way.


\paragraph{Using Adaptive Recommenders in Other Domains}
We chose to use the MovieLens dataset and the RMSE evaluation measure for testing our approach.
The primary reason was to be able to directly evaluate our results towards those of other research thesis.
As this dataset and this error measure is widely used to evaluate recommender systems,
it is natural for a first look at a new approach to use the same notions of accuracy.

However, as mentioned above, the main strength of adaptive recommenders may be
in situations with much more diverse data sources. Social networks or systems
with widely varying sets of items would provide an interesting use case for adaptive recommenders.
The main premise of our approach is that each user and item have differing preferences
for each algorithm. 

Naturally, the more diverse the data and algorithms get,
the more dire the need for adaptive aggregation becomes.
Because of this, using adaptive recommenders in other domains with more variation 
in the data and combined algorithms would be an interesting topic.


\paragraph{Multiple IR Models as Signals}
As mentioned in Chapter \ref{chap:results},
we only tried rank aggregation in a scenario with one IR model.
However, other systems may use multiple IR models
that return a set of ranked items in response to a query.
In the case of personalized search with multiple IR models
and RSs, we would have a large set of differing
input signals:
one from each IR model and one from each RS.

In this case, adaptive recommenders could be used to combine
both the RSs and IR models.
In the same way different RSs have varying performance
for individual users and items, the same should hold
for different IR models.
By using adaptive recommenders we would be able
to adaptively restrict the item space based on the 
current user.
While outside the scope of this thesis,
using multiple IR models would add another adaptive
aspect to the final results list in personalized search.


\paragraph{Using Adaptive Recommenders in Other AI Fields}
We have only considered the notion of latent subjectivity within the field of recommender systems.
However, as briefly mentioned above, the technique should be applicable to many more situations.
Whenever there is a set of prediction algorithms that use different data to produce results,
an adaptive aggregation should be able to combine these in a more nuanced way.

Ensemble learning is a big topic, used in many situations.
By layering recommenders on top of each method in an ensemble, 
we get a system capable of predicting the accuracy of each method.
Naturally, it would be interesting to see how this approach would fare
in other fields such as document classification, document clustering,
curve fitting \cite[p7]{Polikar2006}, and other fields of ensemble learning.


\clearpage
\section{Conclusion}

The information overload problem will always be present.
No matter how elegant solutions one may find,
the fact is that the overwhelming amount of available data
quickly outgrows our ability to use it.
We believe artificial intelligence is crucial to finding a solution.
Only by creating intelligent systems that 
help us filter, sort and consume information can we hope 
to mitigate the overload.

This thesis has explained the \emph{latent subjectivity problem},
and introduced the technique of \emph{adaptive recommenders}
in an attempt to solve it.
We believe this solution is one possible way to minimize the overload problem.
Our technique implicitly, and without any extra work required from each user
adapts how the system models users and items based on past performance.
Our experiments show that this technique is capable of higher accuracy
than standard recommenders and simple aggregation approaches.

Of course, we have only tested our method on a limited 
number of use cases, with a few specific datasets.
This is an important limitation.
Until a method is successfully applied in a real world
situation, claiming progress is premature.
However, we believe more research into 
truly and internally adaptive user modeling systems
would be a worthwhile effort.

On a more general note, we think our notion of adaptive model
aggregation is key to stopping information overload,
regardless of how it is done.
Generalized methods is not enough: only
by creating truly adaptive systems that adapt their
algorithms to each user and item can we achieve a 
system powerful enough to deal with the widely
varying users, and vast scope of items.

We believe many AI methods fail to gain wide acceptance by users
because they lack this extra level of personalization.
As stated through the latent subjectivity problem,
systems should not only tell users what has been predicted,
but also allow flexible and adaptive usage of its internal algorithms.
\emph{After all, a system that insists on being adaptive
in one particular way is not really adaptive at all}.

\hr

\noindent
Information is indeed a curious thing,
and our only way of taming the never ending torrent of 
arriving data is to embrace the wide scope of the information
and of the people who wish to consume it.
Adaptive prediction aggregation takes us one step further towards this goal.

